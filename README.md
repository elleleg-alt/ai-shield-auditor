# ğŸ›¡ï¸ AI Shield Auditor

> **Production-ready security auditing platform for LLM/AI applications**

A comprehensive, self-guided security auditor for AI/LLM systems. Evaluates security posture across identity, data governance, RAG privacy, integrations, model safety, compliance, and deployment.

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Streamlit](https://img.shields.io/badge/streamlit-1.39.0-red.svg)](https://streamlit.io)
[![Docker](https://img.shields.io/badge/docker-ready-brightgreen.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## âœ¨ Features

- ğŸ¯ **Guided Security Audit** - Step-by-step questionnaire across 7 security domains
- ğŸ“Š **Comprehensive Reporting** - PDF and JSON export with actionable recommendations
- ğŸ” **Production-Ready** - Security hardened, rate limited, with structured logging
- ğŸ³ **Deploy Anywhere** - Docker, Cloud Run, ECS, Streamlit Cloud, and more
- ğŸ¤– **LLM-Enhanced** - Optional AI-powered analysis (OpenAI, Anthropic)
- ğŸ“ˆ **Real-time Scoring** - Instant security posture assessment
- ğŸ” **7 Security Domains** - Identity, Data Governance, RAG Privacy, Integrations, Model Safety, Compliance, Deployment

---

## ğŸš€ Quick Start

### Option 1: Automated Setup (Recommended)

```bash
# Clone repository
git clone <your-repo-url>
cd ai-shield-auditor

# Run setup script
chmod +x scripts/setup-local.sh
./scripts/setup-local.sh

# Activate environment
source .venv/bin/activate

# Run application
streamlit run app_enhanced.py
```

Visit `http://localhost:8501`

### Option 2: Manual Setup

```bash
# Create virtual environment
python3 -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Set up environment
cp .env.example .env
# Edit .env with your API keys (optional)

# Run application
streamlit run app.py
```

### Option 3: Docker

```bash
# Using docker-compose (easiest)
docker-compose up -d

# OR build and run manually
docker build -t ai-shield-auditor .
docker run -p 8501:8501 ai-shield-auditor
```

Visit `http://localhost:8501`

---

## ğŸ“‹ What You Get

### Core Features
- âœ… **Interactive Audit Wizard** - User-friendly Streamlit interface
- âœ… **7 Security Categories** - Comprehensive coverage of AI security domains
- âœ… **Instant Scoring** - Real-time security posture assessment
- âœ… **PDF Reports** - Professional audit reports
- âœ… **JSON Export** - CI/CD integration ready
- âœ… **LLM Mode (Optional)** - AI-enhanced findings and recommendations

### Production Features (app_enhanced.py)
- âœ… **Error Handling** - Graceful error recovery
- âœ… **Structured Logging** - JSON logs for production
- âœ… **Rate Limiting** - DDoS protection
- âœ… **Input Validation** - Security hardened
- âœ… **Health Monitoring** - Built-in health checks
- âœ… **Security Headers** - Industry-standard HTTP headers

---

## ğŸ“ Project Structure

```
ai-shield-auditor/
â”œâ”€â”€ app.py                      # Original application
â”œâ”€â”€ app_enhanced.py             # Production-ready version â­
â”œâ”€â”€ Dockerfile                  # Container definition
â”œâ”€â”€ docker-compose.yml          # Orchestration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â”‚
â”œâ”€â”€ core/                       # Core modules
â”‚   â”œâ”€â”€ schema.py              # Data models
â”‚   â”œâ”€â”€ scoring.py             # Scoring logic
â”‚   â”œâ”€â”€ report.py              # PDF generation
â”‚   â”œâ”€â”€ detectors.py           # Platform detection
â”‚   â”œâ”€â”€ utils.py               # Utilities
â”‚   â”œâ”€â”€ logging_config.py      # Logging setup â­
â”‚   â”œâ”€â”€ security.py            # Security utilities â­
â”‚   â””â”€â”€ health.py              # Health checks â­
â”‚
â”œâ”€â”€ audits/                     # Audit modules
â”‚   â”œâ”€â”€ identity.py            # Identity & Access
â”‚   â”œâ”€â”€ data_governance.py     # Data Governance
â”‚   â”œâ”€â”€ rag_privacy.py         # RAG Privacy
â”‚   â”œâ”€â”€ integration_security.py # Integrations
â”‚   â”œâ”€â”€ model_safety.py        # Model Safety
â”‚   â”œâ”€â”€ compliance.py          # Compliance
â”‚   â””â”€â”€ deployment.py          # Deployment Security
â”‚
â”œâ”€â”€ templates/                  # Configuration
â”‚   â”œâ”€â”€ questions.yml          # Audit questions
â”‚   â””â”€â”€ providers.yml          # Platform configs
â”‚
â”œâ”€â”€ scripts/                    # Deployment scripts â­
â”‚   â”œâ”€â”€ setup-local.sh
â”‚   â”œâ”€â”€ deploy-docker.sh
â”‚   â””â”€â”€ deploy-streamlit-cloud.sh
â”‚
â”œâ”€â”€ .github/workflows/          # CI/CD â­
â”‚   â””â”€â”€ deploy.yml
â”‚
â””â”€â”€ docs/                       # Documentation â­
    â”œâ”€â”€ DEPLOYMENT.md
    â”œâ”€â”€ PRODUCTION_CHECKLIST.md
    â””â”€â”€ IMPROVEMENTS_SUMMARY.md
```

â­ = New production-ready additions

---

## ğŸ”§ Configuration

### Environment Variables

Create `.env` file (copy from `.env.example`):

```env
# LLM Provider (optional)
LLM_PROVIDER=openai          # Options: openai, anthropic, none
OPENAI_API_KEY=sk-...        # If using OpenAI
ANTHROPIC_API_KEY=sk-ant-... # If using Anthropic

# Application Settings
LOG_LEVEL=INFO               # Options: DEBUG, INFO, WARNING, ERROR
```

### Modes

**Checklist Mode (Default)**
- No API keys required
- Deterministic scoring
- Fast and free
- Ideal for getting started

**LLM Mode (Optional)**
- Requires API keys
- AI-enhanced analysis
- Smarter recommendations
- Better contextual insights

---

## ğŸ¯ Security Domains

1. **Identity & Access Control**
   - MFA enforcement
   - API key management
   - IAM configuration
   - Key rotation policies

2. **Data Governance**
   - Data classification
   - Encryption (at rest/transit)
   - Data retention
   - PII/PHI handling

3. **RAG Privacy**
   - Document-level ACLs
   - Retrieval security
   - Multi-tenant isolation
   - Cache policies

4. **Integration Security**
   - OAuth scopes
   - API restrictions
   - Webhook verification
   - Third-party connectors

5. **Model Safety**
   - Prompt injection testing
   - Jailbreak prevention
   - Tool call restrictions
   - Safety filters

6. **Compliance**
   - GDPR/HIPAA/FERPA
   - Audit trails
   - Privacy impact assessments
   - Incident response

7. **Deployment Security**
   - Network isolation
   - Container security
   - CI/CD scanning
   - Version control

---

## ğŸš¢ Deployment Options

| Platform | Difficulty | Cost | Best For |
|----------|-----------|------|----------|
| [Streamlit Cloud](DEPLOYMENT.md#streamlit-cloud) | â­ Easy | Free | Quick demos |
| [Docker Local](DEPLOYMENT.md#docker-deployment) | â­â­ Medium | Free | Development |
| [Google Cloud Run](DEPLOYMENT.md#google-cloud-run) | â­â­ Medium | ~$5/mo | Serverless |
| [Railway](DEPLOYMENT.md#railway) | â­â­ Medium | Free tier | Modern apps |
| [Render](DEPLOYMENT.md#render) | â­â­ Medium | $7/mo | Git-based |
| [AWS ECS](DEPLOYMENT.md#aws-ecsfargate) | â­â­â­ Hard | ~$30/mo | Enterprise |

See [DEPLOYMENT.md](DEPLOYMENT.md) for detailed instructions.

---

## ğŸ“š Documentation

- **[DEPLOYMENT.md](DEPLOYMENT.md)** - Complete deployment guide for all platforms
- **[PRODUCTION_CHECKLIST.md](PRODUCTION_CHECKLIST.md)** - Pre-deployment checklist
- **[IMPROVEMENTS_SUMMARY.md](IMPROVEMENTS_SUMMARY.md)** - What's new and improved
- **[QUICKSTART.md](QUICKSTART.md)** - Getting started guide

---

## ğŸ” Usage Example

```bash
# 1. Start the application
streamlit run app_enhanced.py

# 2. In the sidebar, configure your environment:
#    - Select platform (OpenAI, Azure, Anthropic, etc.)
#    - Enable agent mode (if applicable)
#    - Select connectors (Slack, Google Drive, etc.)
#    - Specify vector store (if using RAG)
#    - Identify sensitive data types

# 3. Click "Detect & Lock Environment"

# 4. Answer questions in each category tab

# 5. Click "Run Audit" to generate report

# 6. Export as PDF or JSON
```

---

## ğŸ³ Docker Commands

```bash
# Build image
docker build -t ai-shield-auditor .

# Run container
docker run -p 8501:8501 \
  -e LLM_PROVIDER=openai \
  -e OPENAI_API_KEY=sk-... \
  ai-shield-auditor

# With docker-compose
docker-compose up -d          # Start
docker-compose logs -f        # View logs
docker-compose down           # Stop

# Health check
curl http://localhost:8501/_stcore/health
```

---

## ğŸ§ª Testing

```bash
# Test imports
python -c "from core.schema import AuditReport; print('OK')"

# Test application startup
streamlit run app.py --server.headless=true &
sleep 5
curl -f http://localhost:8501/_stcore/health
```

---

## ğŸ“Š Sample Output

After running an audit, you'll receive:

- **Overall Security Score**: 0-10 rating
- **Risk Level**: Low/Moderate/High
- **Category Breakdown**: Scores for each domain
- **Findings**: Specific security issues identified
- **Recommendations**: Actionable remediation steps
- **PDF Report**: Professional documentation
- **JSON Export**: Machine-readable for CI/CD

---

## ğŸ” Security

This application follows security best practices:

- âœ… Input validation and sanitization
- âœ… Rate limiting (50 requests/minute)
- âœ… Security headers (HSTS, CSP, X-Frame-Options)
- âœ… Non-root Docker container
- âœ… Secrets via environment variables
- âœ… Sensitive data redaction in logs
- âœ… HTTPS recommended for production

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests (if applicable)
5. Submit a pull request

---

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ†˜ Support

- **Documentation**: See `DEPLOYMENT.md` and other docs
- **Issues**: [GitHub Issues](https://github.com/your-repo/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-repo/discussions)

---

## ğŸ—ºï¸ Roadmap

- [ ] Automated security testing integration
- [ ] Multi-language support
- [ ] Custom audit templates
- [ ] API-first mode
- [ ] Team collaboration features
- [ ] Continuous monitoring
- [ ] Integration with SIEM tools

---

## ğŸ™ Acknowledgments

- Streamlit team for the amazing framework
- OWASP for LLM security guidelines
- AI security community for best practices

---

## â­ Star History

If you find this useful, please consider starring the repository!

---

**Built with â¤ï¸ for the AI security community**
